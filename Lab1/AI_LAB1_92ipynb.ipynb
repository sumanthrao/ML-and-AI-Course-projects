{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pos_amazon_cell_phone_reviews.json\") as f:\n",
    "    data = json.load(f)\n",
    "data = data['root']\n",
    "#print(len(data))\n",
    "df_pos = pd.DataFrame(data)\n",
    "summaries_positive = []\n",
    "text_positive = []\n",
    "for i in data:\n",
    "    summaries_positive.append(i['summary'])\n",
    "    text_positive.append(i['text'])\n",
    "label = [1] * 108664\n",
    "df_pos['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pos2 = df_pos[0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"neg_amazon_cell_phone_reviews.json\") as f:\n",
    "    data = json.load(f)\n",
    "summaries_negative=[]\n",
    "text_negative=[]\n",
    "data = data['root']\n",
    "df_neg = pd.DataFrame(data)\n",
    "for i in data:\n",
    "    summaries_negative.append(i['summary'])\n",
    "    text_negative.append(i['text'])\n",
    "label = [0] * len(data)\n",
    "df_neg['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg2 = df_neg[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pos2.append(df_neg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = list(X_train['summary'])\n",
    "summary_test = list(X_test['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(summary)\n",
    "vocab = tokenizer.word_index\n",
    "vocab_counts = tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(summary)\n",
    "sequences_test = tokenizer.texts_to_sequences(summary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_test.index(max(sequences_test,key = lambda x : len(x)))\n",
    "len(max(sequences_test,key = lambda x : len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6321"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_length = len(max(sequences, key = lambda x: len(x)))\n",
    "#pad_length = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X_train = pad_sequences(sequences, maxlen = pad_length)\n",
    "new_X_test =  pad_sequences(sequences_test, maxlen = pad_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  16, 220],\n",
       "       [  0,   0,   0, ...,   0,   0,  45],\n",
       "       [  0,   0,   0, ...,   0,  42, 114],\n",
       "       ..., \n",
       "       [  0,   0,   0, ...,   0,   0,   1],\n",
       "       [  0,   0,   0, ...,  34,  34,  34],\n",
       "       [  0,   0,   0, ...,  36, 149, 163]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1,   54],\n",
       "       [   0,    0,    0, ...,    0, 1346,  123],\n",
       "       [   0,    0,    0, ...,    0,    1,   13],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,   36,    4,   26],\n",
       "       [   0,    0,    0, ...,   65,   47,  103],\n",
       "       [   0,    0,    0, ...,    0,   72,  437]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26623"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Y_train = to_categorical(y_train)\n",
    "new_Y_train\n",
    "#len(vocab)\n",
    "len(new_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6656"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_Y_test = to_categorical(y_test)\n",
    "len(new_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = ''\n",
    "\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding='utf8')\n",
    "\n",
    "for line in f:\n",
    "\n",
    "    values = line.split()\n",
    "\n",
    "    word = values[0]\n",
    "\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "MAX_NB_WORDS = 5000\n",
    "num_words = min(MAX_NB_WORDS, len(vocab) + 1)\n",
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in vocab.items():\n",
    "\n",
    "    if i >= MAX_NB_WORDS:\n",
    "\n",
    "        continue\n",
    "\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "\n",
    "    if embedding_vector is not None:\n",
    "\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3427"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    " \n",
    "    Only computes a batch-wise average of precision.\n",
    " \n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    " \n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab) + 1, 100, input_length=pad_length))\n",
    "model.add(LSTM(256,dropout=0.5,recurrent_dropout=0.2))\n",
    "#model.add(LSTM(128,dropout=0.2,return_sequences=False))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21298 samples, validate on 5325 samples\n",
      "Epoch 1/10\n",
      "21298/21298 [==============================] - 157s - loss: 0.3208 - acc: 0.8570 - precision: 0.8575 - recall: 0.8568 - val_loss: 0.2250 - val_acc: 0.9099 - val_precision: 0.9096 - val_recall: 0.9102\n",
      "Epoch 2/10\n",
      "21298/21298 [==============================] - 153s - loss: 0.1816 - acc: 0.9340 - precision: 0.9341 - recall: 0.9340 - val_loss: 0.2127 - val_acc: 0.9139 - val_precision: 0.9140 - val_recall: 0.9138\n",
      "Epoch 3/10\n",
      "21298/21298 [==============================] - 148s - loss: 0.1459 - acc: 0.9463 - precision: 0.9466 - recall: 0.9460 - val_loss: 0.2241 - val_acc: 0.9147 - val_precision: 0.9146 - val_recall: 0.9149\n",
      "Epoch 4/10\n",
      "21298/21298 [==============================] - 148s - loss: 0.1243 - acc: 0.9546 - precision: 0.9548 - recall: 0.9545 - val_loss: 0.2231 - val_acc: 0.9174 - val_precision: 0.9180 - val_recall: 0.9166\n",
      "Epoch 5/10\n",
      "21298/21298 [==============================] - 149s - loss: 0.1089 - acc: 0.9590 - precision: 0.9591 - recall: 0.9590 - val_loss: 0.2344 - val_acc: 0.9207 - val_precision: 0.9202 - val_recall: 0.9213\n",
      "Epoch 6/10\n",
      "21298/21298 [==============================] - 150s - loss: 0.0988 - acc: 0.9635 - precision: 0.9635 - recall: 0.9636 - val_loss: 0.2334 - val_acc: 0.9142 - val_precision: 0.9140 - val_recall: 0.9144\n",
      "Epoch 7/10\n",
      "21298/21298 [==============================] - 156s - loss: 0.0869 - acc: 0.9673 - precision: 0.9671 - recall: 0.9676 - val_loss: 0.2742 - val_acc: 0.9151 - val_precision: 0.9153 - val_recall: 0.9149\n",
      "Epoch 8/10\n",
      "21298/21298 [==============================] - 155s - loss: 0.0819 - acc: 0.9694 - precision: 0.9693 - recall: 0.9695 - val_loss: 0.2521 - val_acc: 0.9158 - val_precision: 0.9164 - val_recall: 0.9151\n",
      "Epoch 9/10\n",
      "21298/21298 [==============================] - 156s - loss: 0.0749 - acc: 0.9730 - precision: 0.9731 - recall: 0.9730 - val_loss: 0.3037 - val_acc: 0.9192 - val_precision: 0.9193 - val_recall: 0.9191\n",
      "Epoch 10/10\n",
      "21298/21298 [==============================] - 159s - loss: 0.0705 - acc: 0.9734 - precision: 0.9733 - recall: 0.9736 - val_loss: 0.3126 - val_acc: 0.9190 - val_precision: 0.9187 - val_recall: 0.9192\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(new_X_train, new_Y_train, validation_split = 0.20, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.00%\n",
      "Precision: 91.95%\n",
      "Recall: 94.94%\n",
      "F-score: 93.42%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(new_X_test, new_Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "y_pred = model.predict(new_X_test)\n",
    "#y_pred\n",
    "#precision([np.argmax(x) for x in new_Y_test], [np.argmax(x) for x in y_pred])\n",
    "[p, r, f, _] = precision_recall_fscore_support([np.argmax(x) for x in new_Y_test], [np.argmax(x) for x in y_pred], average='binary')\n",
    "#[[int(x[0].round()), int(x[1].round())] for x in y_pred]\n",
    "#new_Y_test\n",
    "#[np.argmax(x) for x in y_pred]\n",
    "print(\"Precision: %.2f%%\" % (p*100))\n",
    "print(\"Recall: %.2f%%\" % (r*100))\n",
    "print(\"F-score: %.2f%%\" % (f*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         2, 92,  1, 44, 20]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Not that great. Don't buy\"\n",
    "review = [review]\n",
    "#print(review)\n",
    "to_check = tokenizer.texts_to_sequences(review)\n",
    "to_check = pad_sequences(to_check, maxlen=pad_length)\n",
    "to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99462402  0.00451099]]\n",
      "Class :  0\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "predict_class = model.predict(to_check)\n",
    "print(predict_class)\n",
    "label = np.argmax(predict_class) \n",
    "print(\"Class : \", label)\n",
    "\n",
    "if(label == 1):\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 22, 32)            109664    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 192,354\n",
      "Trainable params: 192,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "\n",
    "kernel_size = 5\n",
    "filters = 128\n",
    "pool_size = 4\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocab) + 1, 32, input_length=pad_length))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=pool_size))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8064 samples, validate on 1536 samples\n",
      "Epoch 1/5\n",
      "8064/8064 [==============================] - 7s - loss: 0.6015 - acc: 0.6272 - precision: 0.6267 - recall: 0.6261 - val_loss: 0.5030 - val_acc: 0.7051 - val_precision: 0.7051 - val_recall: 0.7051\n",
      "Epoch 2/5\n",
      "8064/8064 [==============================] - 5s - loss: 0.4578 - acc: 0.7388 - precision: 0.7388 - recall: 0.7386 - val_loss: 0.4946 - val_acc: 0.7051 - val_precision: 0.7054 - val_recall: 0.7044\n",
      "Epoch 3/5\n",
      "8064/8064 [==============================] - 5s - loss: 0.4083 - acc: 0.7580 - precision: 0.7566 - recall: 0.7609 - val_loss: 0.5124 - val_acc: 0.7155 - val_precision: 0.7155 - val_recall: 0.7155\n",
      "Epoch 4/5\n",
      "8064/8064 [==============================] - 5s - loss: 0.3855 - acc: 0.7675 - precision: 0.7679 - recall: 0.7670 - val_loss: 0.5326 - val_acc: 0.7012 - val_precision: 0.7012 - val_recall: 0.7012\n",
      "Epoch 5/5\n",
      "8064/8064 [==============================] - 5s - loss: 0.3686 - acc: 0.7757 - precision: 0.7755 - recall: 0.7762 - val_loss: 0.5396 - val_acc: 0.7139 - val_precision: 0.7137 - val_recall: 0.7142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6c3776cf8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_X_train, new_Y_train, validation_split = 0.16, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
